{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8dd9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "abstract = \"\"\"\n",
    "    Despite there being over 200M first-language speakers of the Indonesian language, the language is underrepresented in NLP. We argue that there are three root causes: a lack of annotated datasets, a sparsity\n",
    "of language resources, and a lack of resource standardization. In English, on the other hand, there are\n",
    "ever-increasing numbers of datasets for different tasks (Hermann et al., 2015; Luong and Manning, 2016;\n",
    "Rajpurkar et al., 2018; Agirre et al., 2016), (pre-)trained models for language modelling and language\n",
    "understanding tasks (Devlin et al., 2019; Yang et al., 2019; Radford et al., 2019), and standardized tasks\n",
    "to benchmark research progress (Wang et al., 2019b; Wang et al., 2019a; Williams et al., 2018), all of\n",
    "which have contributed to rapid progress in the field in recent years.\n",
    "    We attempt to redress this situation for Indonesian, as follows. First, we introduce INDOLEM\n",
    "(“Indonesian Language Evaluation Montage”2 ), a comprehensive dataset encompassing seven NLP tasks\n",
    "and eight sub-datasets, five of which are based on previous work and three are novel to this work. As\n",
    "part of this, we standardize data splits and evaluation metrics, to enhance reproducibility and robust\n",
    "benchmarking. These tasks are intended to span a broad range of morpho-syntactic, semantic, and discourse analysis competencies for Indonesian, to be able to benchmark progress in Indonesian NLP. First,\n",
    "for morpho-syntax, we examine part-of-speech (POS) tagging (Dinakaramani et al., 2014), dependency\n",
    "parsing with two Universal Dependency (UD) datasets, and two named entity recognition (NER) tasks\n",
    "using public data. For semantics, we examine sentiment analysis and single-document summarization.\n",
    "For discourse, we create two Twitter-based document coherence tasks: Twitter response prediction (as a\n",
    "multiple-choice task), and Twitter document thread ordering.\n",
    "    Second, we develop and release INDOBERT, a monolingual pre-trained BERT language model for\n",
    "Indonesian (Devlin et al., 2019). This is one of the first monolingual BERT models for the Indonesian\n",
    "language, trained following the best practice in the field.3\n",
    "    Our contributions in this paper are: (1) we release INDOLEM, which is by far the most comprehensive\n",
    "NLP dataset for Indonesian, and intended to provide a benchmark to catalyze further NLP research on\n",
    "the language; (2) as part of INDOLEM, we develop two novel discourse tasks and datasets; and (3)\n",
    "we follow best practice in developing and releasing for general use INDOBERT, a BERT model for\n",
    "Indonesian, which we show to be superior to existing pre-trained models based on INDOLEM. The\n",
    "INDOLEM dataset, INDOBERT model, and all code associated with this paper can be accessed at:\n",
    "https://indolem.github.io.\n",
    "\"\"\"\n",
    "\n",
    "cleaned_abs = abstract.translate(\n",
    "    str.maketrans(\"\", \"\", string.punctuation)\n",
    ")\n",
    "\n",
    "amt_w = len(cleaned_abs.split())\n",
    "print(amt_w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
